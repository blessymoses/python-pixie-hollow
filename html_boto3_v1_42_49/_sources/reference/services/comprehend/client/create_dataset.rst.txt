:doc:`Comprehend <../../comprehend>` / Client / create_dataset

**************
create_dataset
**************



.. py:method:: Comprehend.Client.create_dataset(**kwargs)

  

  Creates a dataset to upload training or test data for a model associated with a flywheel. For more information about datasets, see `Flywheel overview <https://docs.aws.amazon.com/comprehend/latest/dg/flywheels-about.html>`__ in the *Amazon Comprehend Developer Guide*.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/comprehend-2017-11-27/CreateDataset>`_  


  **Request Syntax**
  ::

    response = client.create_dataset(
        FlywheelArn='string',
        DatasetName='string',
        DatasetType='TRAIN'|'TEST',
        Description='string',
        InputDataConfig={
            'AugmentedManifests': [
                {
                    'AttributeNames': [
                        'string',
                    ],
                    'S3Uri': 'string',
                    'AnnotationDataS3Uri': 'string',
                    'SourceDocumentsS3Uri': 'string',
                    'DocumentType': 'PLAIN_TEXT_DOCUMENT'|'SEMI_STRUCTURED_DOCUMENT'
                },
            ],
            'DataFormat': 'COMPREHEND_CSV'|'AUGMENTED_MANIFEST',
            'DocumentClassifierInputDataConfig': {
                'S3Uri': 'string',
                'LabelDelimiter': 'string'
            },
            'EntityRecognizerInputDataConfig': {
                'Annotations': {
                    'S3Uri': 'string'
                },
                'Documents': {
                    'S3Uri': 'string',
                    'InputFormat': 'ONE_DOC_PER_FILE'|'ONE_DOC_PER_LINE'
                },
                'EntityList': {
                    'S3Uri': 'string'
                }
            }
        },
        ClientRequestToken='string',
        Tags=[
            {
                'Key': 'string',
                'Value': 'string'
            },
        ]
    )
    
  :type FlywheelArn: string
  :param FlywheelArn: **[REQUIRED]** 

    The Amazon Resource Number (ARN) of the flywheel of the flywheel to receive the data.

    

  
  :type DatasetName: string
  :param DatasetName: **[REQUIRED]** 

    Name of the dataset.

    

  
  :type DatasetType: string
  :param DatasetType: 

    The dataset type. You can specify that the data in a dataset is for training the model or for testing the model.

    

  
  :type Description: string
  :param Description: 

    Description of the dataset.

    

  
  :type InputDataConfig: dict
  :param InputDataConfig: **[REQUIRED]** 

    Information about the input data configuration. The type of input data varies based on the format of the input and whether the data is for a classifier model or an entity recognition model.

    

  
    - **AugmentedManifests** *(list) --* 

      A list of augmented manifest files that provide training data for your custom model. An augmented manifest file is a labeled dataset that is produced by Amazon SageMaker Ground Truth.

      

    
      - *(dict) --* 

        An augmented manifest file that provides training data for your custom model. An augmented manifest file is a labeled dataset that is produced by Amazon SageMaker Ground Truth.

        

      
        - **AttributeNames** *(list) --* **[REQUIRED]** 

          The JSON attribute that contains the annotations for your training documents. The number of attribute names that you specify depends on whether your augmented manifest file is the output of a single labeling job or a chained labeling job.

           

          If your file is the output of a single labeling job, specify the LabelAttributeName key that was used when the job was created in Ground Truth.

           

          If your file is the output of a chained labeling job, specify the LabelAttributeName key for one or more jobs in the chain. Each LabelAttributeName key provides the annotations from an individual job.

          

        
          - *(string) --* 

          
      
        - **S3Uri** *(string) --* **[REQUIRED]** 

          The Amazon S3 location of the augmented manifest file.

          

        
        - **AnnotationDataS3Uri** *(string) --* 

          The S3 prefix to the annotation files that are referred in the augmented manifest file.

          

        
        - **SourceDocumentsS3Uri** *(string) --* 

          The S3 prefix to the source files (PDFs) that are referred to in the augmented manifest file.

          

        
        - **DocumentType** *(string) --* 

          The type of augmented manifest. If you don't specify, the default is PlainTextDocument.

           

          ``PLAIN_TEXT_DOCUMENT`` A document type that represents any unicode text that is encoded in UTF-8.

          

        
      
  
    - **DataFormat** *(string) --* 

      ``COMPREHEND_CSV``: The data format is a two-column CSV file, where the first column contains labels and the second column contains documents.

       

      ``AUGMENTED_MANIFEST``: The data format

      

    
    - **DocumentClassifierInputDataConfig** *(dict) --* 

      The input properties for training a document classifier model.

       

      For more information on how the input file is formatted, see `Preparing training data <https://docs.aws.amazon.com/comprehend/latest/dg/prep-classifier-data.html>`__ in the Comprehend Developer Guide.

      

    
      - **S3Uri** *(string) --* **[REQUIRED]** 

        The Amazon S3 URI for the input data. The S3 bucket must be in the same Region as the API endpoint that you are calling. The URI can point to a single input file or it can provide the prefix for a collection of input files.

         

        For example, if you use the URI ``S3://bucketName/prefix``, if the prefix is a single file, Amazon Comprehend uses that file as input. If more than one file begins with the prefix, Amazon Comprehend uses all of them as input.

         

        This parameter is required if you set ``DataFormat`` to ``COMPREHEND_CSV``.

        

      
      - **LabelDelimiter** *(string) --* 

        Indicates the delimiter used to separate each label for training a multi-label classifier. The default delimiter between labels is a pipe (|). You can use a different character as a delimiter (if it's an allowed character) by specifying it under Delimiter for labels. If the training documents use a delimiter other than the default or the delimiter you specify, the labels on that line will be combined to make a single unique label, such as LABELLABELLABEL.

        

      
    
    - **EntityRecognizerInputDataConfig** *(dict) --* 

      The input properties for training an entity recognizer model.

      

    
      - **Annotations** *(dict) --* 

        The S3 location of the annotation documents for your custom entity recognizer.

        

      
        - **S3Uri** *(string) --* **[REQUIRED]** 

          Specifies the Amazon S3 location where the training documents for an entity recognizer are located. The URI must be in the same Region as the API endpoint that you are calling.

          

        
      
      - **Documents** *(dict) --* **[REQUIRED]** 

        The format and location of the training documents for your custom entity recognizer.

        

      
        - **S3Uri** *(string) --* **[REQUIRED]** 

          Specifies the Amazon S3 location where the documents for the dataset are located.

          

        
        - **InputFormat** *(string) --* 

          Specifies how the text in an input file should be processed. This is optional, and the default is ONE_DOC_PER_LINE. ONE_DOC_PER_FILE - Each file is considered a separate document. Use this option when you are processing large documents, such as newspaper articles or scientific papers. ONE_DOC_PER_LINE - Each line in a file is considered a separate document. Use this option when you are processing many short documents, such as text messages.

          

        
      
      - **EntityList** *(dict) --* 

        The S3 location of the entity list for your custom entity recognizer.

        

      
        - **S3Uri** *(string) --* **[REQUIRED]** 

          Specifies the Amazon S3 location where the entity list is located.

          

        
      
    
  
  :type ClientRequestToken: string
  :param ClientRequestToken: 

    A unique identifier for the request. If you don't set the client request token, Amazon Comprehend generates one.

    This field is autopopulated if not provided.

  
  :type Tags: list
  :param Tags: 

    Tags for the dataset.

    

  
    - *(dict) --* 

      A key-value pair that adds as a metadata to a resource used by Amazon Comprehend. For example, a tag with the key-value pair ‘Department’:’Sales’ might be added to a resource to indicate its use by a particular department.

      

    
      - **Key** *(string) --* **[REQUIRED]** 

        The initial part of a key-value pair that forms a tag associated with a given resource. For instance, if you want to show which resources are used by which departments, you might use “Department” as the key portion of the pair, with multiple possible values such as “sales,” “legal,” and “administration.”

        

      
      - **Value** *(string) --* 

        The second part of a key-value pair that forms a tag associated with a given resource. For instance, if you want to show which resources are used by which departments, you might use “Department” as the initial (key) portion of the pair, with a value of “sales” to indicate the sales department.

        

      
    

  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'DatasetArn': 'string'
      }
      
    **Response Structure**

    

    - *(dict) --* 
      

      - **DatasetArn** *(string) --* 

        The ARN of the dataset.

        
  
  **Exceptions**
  
  *   :py:class:`Comprehend.Client.exceptions.InvalidRequestException`

  
  *   :py:class:`Comprehend.Client.exceptions.ResourceInUseException`

  
  *   :py:class:`Comprehend.Client.exceptions.TooManyTagsException`

  
  *   :py:class:`Comprehend.Client.exceptions.TooManyRequestsException`

  
  *   :py:class:`Comprehend.Client.exceptions.ResourceLimitExceededException`

  
  *   :py:class:`Comprehend.Client.exceptions.ResourceNotFoundException`

  
  *   :py:class:`Comprehend.Client.exceptions.InternalServerException`

  