:doc:`LookoutEquipment <../../lookoutequipment>` / Client / list_inference_executions

*************************
list_inference_executions
*************************



.. py:method:: LookoutEquipment.Client.list_inference_executions(**kwargs)

  

  Lists all inference executions that have been performed by the specified inference scheduler.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/lookoutequipment-2020-12-15/ListInferenceExecutions>`_  


  **Request Syntax**
  ::

    response = client.list_inference_executions(
        NextToken='string',
        MaxResults=123,
        InferenceSchedulerName='string',
        DataStartTimeAfter=datetime(2015, 1, 1),
        DataEndTimeBefore=datetime(2015, 1, 1),
        Status='IN_PROGRESS'|'SUCCESS'|'FAILED'
    )
    
  :type NextToken: string
  :param NextToken: 

    An opaque pagination token indicating where to continue the listing of inference executions.

    

  
  :type MaxResults: integer
  :param MaxResults: 

    Specifies the maximum number of inference executions to list.

    

  
  :type InferenceSchedulerName: string
  :param InferenceSchedulerName: **[REQUIRED]** 

    The name of the inference scheduler for the inference execution listed.

    

  
  :type DataStartTimeAfter: datetime
  :param DataStartTimeAfter: 

    The time reference in the inferenced dataset after which Amazon Lookout for Equipment started the inference execution.

    

  
  :type DataEndTimeBefore: datetime
  :param DataEndTimeBefore: 

    The time reference in the inferenced dataset before which Amazon Lookout for Equipment stopped the inference execution.

    

  
  :type Status: string
  :param Status: 

    The status of the inference execution.

    

  
  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'NextToken': 'string',
          'InferenceExecutionSummaries': [
              {
                  'ModelName': 'string',
                  'ModelArn': 'string',
                  'InferenceSchedulerName': 'string',
                  'InferenceSchedulerArn': 'string',
                  'ScheduledStartTime': datetime(2015, 1, 1),
                  'DataStartTime': datetime(2015, 1, 1),
                  'DataEndTime': datetime(2015, 1, 1),
                  'DataInputConfiguration': {
                      'S3InputConfiguration': {
                          'Bucket': 'string',
                          'Prefix': 'string'
                      },
                      'InputTimeZoneOffset': 'string',
                      'InferenceInputNameConfiguration': {
                          'TimestampFormat': 'string',
                          'ComponentTimestampDelimiter': 'string'
                      }
                  },
                  'DataOutputConfiguration': {
                      'S3OutputConfiguration': {
                          'Bucket': 'string',
                          'Prefix': 'string'
                      },
                      'KmsKeyId': 'string'
                  },
                  'CustomerResultObject': {
                      'Bucket': 'string',
                      'Key': 'string'
                  },
                  'Status': 'IN_PROGRESS'|'SUCCESS'|'FAILED',
                  'FailedReason': 'string',
                  'ModelVersion': 123,
                  'ModelVersionArn': 'string'
              },
          ]
      }
      
    **Response Structure**

    

    - *(dict) --* 
      

      - **NextToken** *(string) --* 

        An opaque pagination token indicating where to continue the listing of inference executions.

        
      

      - **InferenceExecutionSummaries** *(list) --* 

        Provides an array of information about the individual inference executions returned from the ``ListInferenceExecutions`` operation, including model used, inference scheduler, data configuration, and so on.

         

        .. note::

          

          If you don't supply the ``InferenceSchedulerName`` request parameter, or if you supply the name of an inference scheduler that doesn't exist, ``ListInferenceExecutions`` returns an empty array in ``InferenceExecutionSummaries``.

          

        
        

        - *(dict) --* 

          Contains information about the specific inference execution, including input and output data configuration, inference scheduling information, status, and so on.

          
          

          - **ModelName** *(string) --* 

            The name of the machine learning model being used for the inference execution.

            
          

          - **ModelArn** *(string) --* 

            The Amazon Resource Name (ARN) of the machine learning model used for the inference execution.

            
          

          - **InferenceSchedulerName** *(string) --* 

            The name of the inference scheduler being used for the inference execution.

            
          

          - **InferenceSchedulerArn** *(string) --* 

            The Amazon Resource Name (ARN) of the inference scheduler being used for the inference execution.

            
          

          - **ScheduledStartTime** *(datetime) --* 

            Indicates the start time at which the inference scheduler began the specific inference execution.

            
          

          - **DataStartTime** *(datetime) --* 

            Indicates the time reference in the dataset at which the inference execution began.

            
          

          - **DataEndTime** *(datetime) --* 

            Indicates the time reference in the dataset at which the inference execution stopped.

            
          

          - **DataInputConfiguration** *(dict) --* 

            Specifies configuration information for the input data for the inference scheduler, including delimiter, format, and dataset location.

            
            

            - **S3InputConfiguration** *(dict) --* 

              Specifies configuration information for the input data for the inference, including Amazon S3 location of input data.

              
              

              - **Bucket** *(string) --* 

                The bucket containing the input dataset for the inference.

                
              

              - **Prefix** *(string) --* 

                The prefix for the S3 bucket used for the input data for the inference.

                
          
            

            - **InputTimeZoneOffset** *(string) --* 

              Indicates the difference between your time zone and Coordinated Universal Time (UTC).

              
            

            - **InferenceInputNameConfiguration** *(dict) --* 

              Specifies configuration information for the input data for the inference, including timestamp format and delimiter.

              
              

              - **TimestampFormat** *(string) --* 

                The format of the timestamp, whether Epoch time, or standard, with or without hyphens (-).

                
              

              - **ComponentTimestampDelimiter** *(string) --* 

                Indicates the delimiter character used between items in the data.

                
          
        
          

          - **DataOutputConfiguration** *(dict) --* 

            Specifies configuration information for the output results from for the inference execution, including the output Amazon S3 location.

            
            

            - **S3OutputConfiguration** *(dict) --* 

              Specifies configuration information for the output results from for the inference, output S3 location.

              
              

              - **Bucket** *(string) --* 

                The bucket containing the output results from the inference

                
              

              - **Prefix** *(string) --* 

                The prefix for the S3 bucket used for the output results from the inference.

                
          
            

            - **KmsKeyId** *(string) --* 

              The ID number for the KMS key key used to encrypt the inference output.

              
        
          

          - **CustomerResultObject** *(dict) --* 

            The S3 object that the inference execution results were uploaded to.

            
            

            - **Bucket** *(string) --* 

              The name of the specific S3 bucket.

              
            

            - **Key** *(string) --* 

              The Amazon Web Services Key Management Service (KMS key) key being used to encrypt the S3 object. Without this key, data in the bucket is not accessible.

              
        
          

          - **Status** *(string) --* 

            Indicates the status of the inference execution.

            
          

          - **FailedReason** *(string) --* 

            Specifies the reason for failure when an inference execution has failed.

            
          

          - **ModelVersion** *(integer) --* 

            The model version used for the inference execution.

            
          

          - **ModelVersionArn** *(string) --* 

            The Amazon Resource Number (ARN) of the model version used for the inference execution.

            
      
    
  
  **Exceptions**
  
  *   :py:class:`LookoutEquipment.Client.exceptions.ValidationException`

  
  *   :py:class:`LookoutEquipment.Client.exceptions.ThrottlingException`

  
  *   :py:class:`LookoutEquipment.Client.exceptions.ResourceNotFoundException`

  
  *   :py:class:`LookoutEquipment.Client.exceptions.AccessDeniedException`

  
  *   :py:class:`LookoutEquipment.Client.exceptions.InternalServerException`

  