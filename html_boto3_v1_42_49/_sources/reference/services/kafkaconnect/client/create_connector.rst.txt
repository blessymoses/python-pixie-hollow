:doc:`KafkaConnect <../../kafkaconnect>` / Client / create_connector

****************
create_connector
****************



.. py:method:: KafkaConnect.Client.create_connector(**kwargs)

  

  Creates a connector using the specified properties.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/kafkaconnect-2021-09-14/CreateConnector>`_  


  **Request Syntax**
  ::

    response = client.create_connector(
        capacity={
            'autoScaling': {
                'maxWorkerCount': 123,
                'mcuCount': 123,
                'minWorkerCount': 123,
                'scaleInPolicy': {
                    'cpuUtilizationPercentage': 123
                },
                'scaleOutPolicy': {
                    'cpuUtilizationPercentage': 123
                },
                'maxAutoscalingTaskCount': 123
            },
            'provisionedCapacity': {
                'mcuCount': 123,
                'workerCount': 123
            }
        },
        connectorConfiguration={
            'string': 'string'
        },
        connectorDescription='string',
        connectorName='string',
        kafkaCluster={
            'apacheKafkaCluster': {
                'bootstrapServers': 'string',
                'vpc': {
                    'securityGroups': [
                        'string',
                    ],
                    'subnets': [
                        'string',
                    ]
                }
            }
        },
        kafkaClusterClientAuthentication={
            'authenticationType': 'NONE'|'IAM'
        },
        kafkaClusterEncryptionInTransit={
            'encryptionType': 'PLAINTEXT'|'TLS'
        },
        kafkaConnectVersion='string',
        logDelivery={
            'workerLogDelivery': {
                'cloudWatchLogs': {
                    'enabled': True|False,
                    'logGroup': 'string'
                },
                'firehose': {
                    'deliveryStream': 'string',
                    'enabled': True|False
                },
                's3': {
                    'bucket': 'string',
                    'enabled': True|False,
                    'prefix': 'string'
                }
            }
        },
        networkType='IPV4'|'DUAL',
        plugins=[
            {
                'customPlugin': {
                    'customPluginArn': 'string',
                    'revision': 123
                }
            },
        ],
        serviceExecutionRoleArn='string',
        workerConfiguration={
            'revision': 123,
            'workerConfigurationArn': 'string'
        },
        tags={
            'string': 'string'
        }
    )
    
  :type capacity: dict
  :param capacity: **[REQUIRED]** 

    Information about the capacity allocated to the connector. Exactly one of the two properties must be specified.

    

  
    - **autoScaling** *(dict) --* 

      Information about the auto scaling parameters for the connector.

      

    
      - **maxWorkerCount** *(integer) --* **[REQUIRED]** 

        The maximum number of workers allocated to the connector.

        

      
      - **mcuCount** *(integer) --* **[REQUIRED]** 

        The number of microcontroller units (MCUs) allocated to each connector worker. The valid values are 1,2,4,8.

        

      
      - **minWorkerCount** *(integer) --* **[REQUIRED]** 

        The minimum number of workers allocated to the connector.

        

      
      - **scaleInPolicy** *(dict) --* 

        The scale-in policy for the connector.

        

      
        - **cpuUtilizationPercentage** *(integer) --* **[REQUIRED]** 

          Specifies the CPU utilization percentage threshold at which you want connector scale in to be triggered.

          

        
      
      - **scaleOutPolicy** *(dict) --* 

        The scale-out policy for the connector.

        

      
        - **cpuUtilizationPercentage** *(integer) --* **[REQUIRED]** 

          The CPU utilization percentage threshold at which you want connector scale out to be triggered.

          

        
      
      - **maxAutoscalingTaskCount** *(integer) --* 

        The maximum number of tasks allocated to the connector during autoscaling operations. Must be at least equal to maxWorkerCount.

        

      
    
    - **provisionedCapacity** *(dict) --* 

      Details about a fixed capacity allocated to a connector.

      

    
      - **mcuCount** *(integer) --* **[REQUIRED]** 

        The number of microcontroller units (MCUs) allocated to each connector worker. The valid values are 1,2,4,8.

        

      
      - **workerCount** *(integer) --* **[REQUIRED]** 

        The number of workers that are allocated to the connector.

        

      
    
  
  :type connectorConfiguration: dict
  :param connectorConfiguration: **[REQUIRED]** 

    A map of keys to values that represent the configuration for the connector.

    

  
    - *(string) --* 

    
      - *(string) --* 

      


  :type connectorDescription: string
  :param connectorDescription: 

    A summary description of the connector.

    

  
  :type connectorName: string
  :param connectorName: **[REQUIRED]** 

    The name of the connector.

    

  
  :type kafkaCluster: dict
  :param kafkaCluster: **[REQUIRED]** 

    Specifies which Apache Kafka cluster to connect to.

    

  
    - **apacheKafkaCluster** *(dict) --* **[REQUIRED]** 

      The Apache Kafka cluster to which the connector is connected.

      

    
      - **bootstrapServers** *(string) --* **[REQUIRED]** 

        The bootstrap servers of the cluster.

        

      
      - **vpc** *(dict) --* **[REQUIRED]** 

        Details of an Amazon VPC which has network connectivity to the Apache Kafka cluster.

        

      
        - **securityGroups** *(list) --* 

          The security groups for the connector.

          

        
          - *(string) --* 

          
      
        - **subnets** *(list) --* **[REQUIRED]** 

          The subnets for the connector.

          

        
          - *(string) --* 

          
      
      
    
  
  :type kafkaClusterClientAuthentication: dict
  :param kafkaClusterClientAuthentication: **[REQUIRED]** 

    Details of the client authentication used by the Apache Kafka cluster.

    

  
    - **authenticationType** *(string) --* **[REQUIRED]** 

      The type of client authentication used to connect to the Apache Kafka cluster. Value NONE means that no client authentication is used.

      

    
  
  :type kafkaClusterEncryptionInTransit: dict
  :param kafkaClusterEncryptionInTransit: **[REQUIRED]** 

    Details of encryption in transit to the Apache Kafka cluster.

    

  
    - **encryptionType** *(string) --* **[REQUIRED]** 

      The type of encryption in transit to the Apache Kafka cluster.

      

    
  
  :type kafkaConnectVersion: string
  :param kafkaConnectVersion: **[REQUIRED]** 

    The version of Kafka Connect. It has to be compatible with both the Apache Kafka cluster's version and the plugins.

    

  
  :type logDelivery: dict
  :param logDelivery: 

    Details about log delivery.

    

  
    - **workerLogDelivery** *(dict) --* **[REQUIRED]** 

      The workers can send worker logs to different destination types. This configuration specifies the details of these destinations.

      

    
      - **cloudWatchLogs** *(dict) --* 

        Details about delivering logs to Amazon CloudWatch Logs.

        

      
        - **enabled** *(boolean) --* **[REQUIRED]** 

          Whether log delivery to Amazon CloudWatch Logs is enabled.

          

        
        - **logGroup** *(string) --* 

          The name of the CloudWatch log group that is the destination for log delivery.

          

        
      
      - **firehose** *(dict) --* 

        Details about delivering logs to Amazon Kinesis Data Firehose.

        

      
        - **deliveryStream** *(string) --* 

          The name of the Kinesis Data Firehose delivery stream that is the destination for log delivery.

          

        
        - **enabled** *(boolean) --* **[REQUIRED]** 

          Specifies whether connector logs get delivered to Amazon Kinesis Data Firehose.

          

        
      
      - **s3** *(dict) --* 

        Details about delivering logs to Amazon S3.

        

      
        - **bucket** *(string) --* 

          The name of the S3 bucket that is the destination for log delivery.

          

        
        - **enabled** *(boolean) --* **[REQUIRED]** 

          Specifies whether connector logs get sent to the specified Amazon S3 destination.

          

        
        - **prefix** *(string) --* 

          The S3 prefix that is the destination for log delivery.

          

        
      
    
  
  :type networkType: string
  :param networkType: 

    The network type of the connector. It gives connectors connectivity to either IPv4 (IPV4) or IPv4 and IPv6 (DUAL) destinations. Defaults to IPV4.

    

  
  :type plugins: list
  :param plugins: **[REQUIRED]** 

    

    .. warning::

      

      Amazon MSK Connect does not currently support specifying multiple plugins as a list. To use more than one plugin for your connector, you can create a single custom plugin using a ZIP file that bundles multiple plugins together.

      

     

    Specifies which plugin to use for the connector. You must specify a single-element list containing one ``customPlugin`` object.

    

    

  
    - *(dict) --* 

      A plugin is an Amazon Web Services resource that contains the code that defines your connector logic.

      

    
      - **customPlugin** *(dict) --* **[REQUIRED]** 

        Details about a custom plugin.

        

      
        - **customPluginArn** *(string) --* **[REQUIRED]** 

          The Amazon Resource Name (ARN) of the custom plugin.

          

        
        - **revision** *(integer) --* **[REQUIRED]** 

          The revision of the custom plugin.

          

        
      
    

  :type serviceExecutionRoleArn: string
  :param serviceExecutionRoleArn: **[REQUIRED]** 

    The Amazon Resource Name (ARN) of the IAM role used by the connector to access the Amazon Web Services resources that it needs. The types of resources depends on the logic of the connector. For example, a connector that has Amazon S3 as a destination must have permissions that allow it to write to the S3 destination bucket.

    

  
  :type workerConfiguration: dict
  :param workerConfiguration: 

    Specifies which worker configuration to use with the connector.

    

  
    - **revision** *(integer) --* **[REQUIRED]** 

      The revision of the worker configuration.

      

    
    - **workerConfigurationArn** *(string) --* **[REQUIRED]** 

      The Amazon Resource Name (ARN) of the worker configuration.

      

    
  
  :type tags: dict
  :param tags: 

    The tags you want to attach to the connector.

    

  
    - *(string) --* 

    
      - *(string) --* 

      


  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'connectorArn': 'string',
          'connectorName': 'string',
          'connectorState': 'RUNNING'|'CREATING'|'UPDATING'|'DELETING'|'FAILED'
      }
      
    **Response Structure**

    

    - *(dict) --* 
      

      - **connectorArn** *(string) --* 

        The Amazon Resource Name (ARN) that Amazon assigned to the connector.

        
      

      - **connectorName** *(string) --* 

        The name of the connector.

        
      

      - **connectorState** *(string) --* 

        The state of the connector.

        
  
  **Exceptions**
  
  *   :py:class:`KafkaConnect.Client.exceptions.ConflictException`

  
  *   :py:class:`KafkaConnect.Client.exceptions.NotFoundException`

  
  *   :py:class:`KafkaConnect.Client.exceptions.BadRequestException`

  
  *   :py:class:`KafkaConnect.Client.exceptions.ForbiddenException`

  
  *   :py:class:`KafkaConnect.Client.exceptions.ServiceUnavailableException`

  
  *   :py:class:`KafkaConnect.Client.exceptions.TooManyRequestsException`

  
  *   :py:class:`KafkaConnect.Client.exceptions.UnauthorizedException`

  
  *   :py:class:`KafkaConnect.Client.exceptions.InternalServerErrorException`

  