:doc:`Rekognition <../../rekognition>` / Client / start_segment_detection

***********************
start_segment_detection
***********************



.. py:method:: Rekognition.Client.start_segment_detection(**kwargs)

  

  Starts asynchronous detection of segment detection in a stored video.

   

  Amazon Rekognition Video can detect segments in a video stored in an Amazon S3 bucket. Use  Video to specify the bucket name and the filename of the video. ``StartSegmentDetection`` returns a job identifier ( ``JobId``) which you use to get the results of the operation. When segment detection is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic that you specify in ``NotificationChannel``.

   

  You can use the ``Filters`` (  StartSegmentDetectionFilters) input parameter to specify the minimum detection confidence returned in the response. Within ``Filters``, use ``ShotFilter`` (  StartShotDetectionFilter) to filter detected shots. Use ``TechnicalCueFilter`` (  StartTechnicalCueDetectionFilter) to filter technical cues.

   

  To get the results of the segment detection operation, first check that the status value published to the Amazon SNS topic is ``SUCCEEDED``. if so, call  GetSegmentDetection and pass the job identifier ( ``JobId``) from the initial call to ``StartSegmentDetection``.

   

  For more information, see Detecting video segments in stored video in the Amazon Rekognition Developer Guide.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/rekognition-2016-06-27/StartSegmentDetection>`_  


  **Request Syntax**
  ::

    response = client.start_segment_detection(
        Video={
            'S3Object': {
                'Bucket': 'string',
                'Name': 'string',
                'Version': 'string'
            }
        },
        ClientRequestToken='string',
        NotificationChannel={
            'SNSTopicArn': 'string',
            'RoleArn': 'string'
        },
        JobTag='string',
        Filters={
            'TechnicalCueFilter': {
                'MinSegmentConfidence': ...,
                'BlackFrame': {
                    'MaxPixelThreshold': ...,
                    'MinCoveragePercentage': ...
                }
            },
            'ShotFilter': {
                'MinSegmentConfidence': ...
            }
        },
        SegmentTypes=[
            'TECHNICAL_CUE'|'SHOT',
        ]
    )
    
  :type Video: dict
  :param Video: **[REQUIRED]** 

    Video file stored in an Amazon S3 bucket. Amazon Rekognition video start operations such as  StartLabelDetection use ``Video`` to specify a video for analysis. The supported file formats are .mp4, .mov and .avi.

    

  
    - **S3Object** *(dict) --* 

      The Amazon S3 bucket name and file name for the video.

      

    
      - **Bucket** *(string) --* 

        Name of the S3 bucket.

        

      
      - **Name** *(string) --* 

        S3 object key name.

        

      
      - **Version** *(string) --* 

        If the bucket is versioning enabled, you can specify the object version.

        

      
    
  
  :type ClientRequestToken: string
  :param ClientRequestToken: 

    Idempotent token used to identify the start request. If you use the same token with multiple ``StartSegmentDetection`` requests, the same ``JobId`` is returned. Use ``ClientRequestToken`` to prevent the same job from being accidently started more than once.

    

  
  :type NotificationChannel: dict
  :param NotificationChannel: 

    The ARN of the Amazon SNS topic to which you want Amazon Rekognition Video to publish the completion status of the segment detection operation. Note that the Amazon SNS topic must have a topic name that begins with *AmazonRekognition* if you are using the AmazonRekognitionServiceRole permissions policy to access the topic.

    

  
    - **SNSTopicArn** *(string) --* **[REQUIRED]** 

      The Amazon SNS topic to which Amazon Rekognition posts the completion status.

      

    
    - **RoleArn** *(string) --* **[REQUIRED]** 

      The ARN of an IAM role that gives Amazon Rekognition publishing permissions to the Amazon SNS topic.

      

    
  
  :type JobTag: string
  :param JobTag: 

    An identifier you specify that's returned in the completion notification that's published to your Amazon Simple Notification Service topic. For example, you can use ``JobTag`` to group related jobs and identify them in the completion notification.

    

  
  :type Filters: dict
  :param Filters: 

    Filters for technical cue or shot detection.

    

  
    - **TechnicalCueFilter** *(dict) --* 

      Filters that are specific to technical cues.

      

    
      - **MinSegmentConfidence** *(float) --* 

        Specifies the minimum confidence that Amazon Rekognition Video must have in order to return a detected segment. Confidence represents how certain Amazon Rekognition is that a segment is correctly identified. 0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition Video doesn't return any segments with a confidence level lower than this specified value.

         

        If you don't specify ``MinSegmentConfidence``, ``GetSegmentDetection`` returns segments with confidence values greater than or equal to 50 percent.

        

      
      - **BlackFrame** *(dict) --* 

        A filter that allows you to control the black frame detection by specifying the black levels and pixel coverage of black pixels in a frame. Videos can come from multiple sources, formats, and time periods, with different standards and varying noise levels for black frames that need to be accounted for.

        

      
        - **MaxPixelThreshold** *(float) --* 

          A threshold used to determine the maximum luminance value for a pixel to be considered black. In a full color range video, luminance values range from 0-255. A pixel value of 0 is pure black, and the most strict filter. The maximum black pixel value is computed as follows: max_black_pixel_value = minimum_luminance + MaxPixelThreshold *luminance_range.

           

          For example, for a full range video with BlackPixelThreshold = 0.1, max_black_pixel_value is 0 + 0.1 * (255-0) = 25.5.

           

          The default value of MaxPixelThreshold is 0.2, which maps to a max_black_pixel_value of 51 for a full range video. You can lower this threshold to be more strict on black levels.

          

        
        - **MinCoveragePercentage** *(float) --* 

          The minimum percentage of pixels in a frame that need to have a luminance below the max_black_pixel_value for a frame to be considered a black frame. Luminance is calculated using the BT.709 matrix.

           

          The default value is 99, which means at least 99% of all pixels in the frame are black pixels as per the ``MaxPixelThreshold`` set. You can reduce this value to allow more noise on the black frame.

          

        
      
    
    - **ShotFilter** *(dict) --* 

      Filters that are specific to shot detections.

      

    
      - **MinSegmentConfidence** *(float) --* 

        Specifies the minimum confidence that Amazon Rekognition Video must have in order to return a detected segment. Confidence represents how certain Amazon Rekognition is that a segment is correctly identified. 0 is the lowest confidence. 100 is the highest confidence. Amazon Rekognition Video doesn't return any segments with a confidence level lower than this specified value.

         

        If you don't specify ``MinSegmentConfidence``, the ``GetSegmentDetection`` returns segments with confidence values greater than or equal to 50 percent.

        

      
    
  
  :type SegmentTypes: list
  :param SegmentTypes: **[REQUIRED]** 

    An array of segment types to detect in the video. Valid values are TECHNICAL_CUE and SHOT.

    

  
    - *(string) --* 

    

  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'JobId': 'string'
      }
      
    **Response Structure**

    

    - *(dict) --* 
      

      - **JobId** *(string) --* 

        Unique identifier for the segment detection job. The ``JobId`` is returned from ``StartSegmentDetection``.

        
  
  **Exceptions**
  
  *   :py:class:`Rekognition.Client.exceptions.AccessDeniedException`

  
  *   :py:class:`Rekognition.Client.exceptions.IdempotentParameterMismatchException`

  
  *   :py:class:`Rekognition.Client.exceptions.InvalidParameterException`

  
  *   :py:class:`Rekognition.Client.exceptions.InvalidS3ObjectException`

  
  *   :py:class:`Rekognition.Client.exceptions.InternalServerError`

  
  *   :py:class:`Rekognition.Client.exceptions.VideoTooLargeException`

  
  *   :py:class:`Rekognition.Client.exceptions.ProvisionedThroughputExceededException`

  
  *   :py:class:`Rekognition.Client.exceptions.LimitExceededException`

  
  *   :py:class:`Rekognition.Client.exceptions.ThrottlingException`

  