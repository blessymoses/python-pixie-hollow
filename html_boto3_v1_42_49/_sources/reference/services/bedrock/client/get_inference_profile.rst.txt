:doc:`Bedrock <../../bedrock>` / Client / get_inference_profile

*********************
get_inference_profile
*********************



.. py:method:: Bedrock.Client.get_inference_profile(**kwargs)

  

  Gets information about an inference profile. For more information, see `Increase throughput and resilience with cross-region inference in Amazon Bedrock <https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html>`__. in the Amazon Bedrock User Guide.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/bedrock-2023-04-20/GetInferenceProfile>`_  


  **Request Syntax**
  ::

    response = client.get_inference_profile(
        inferenceProfileIdentifier='string'
    )
    
  :type inferenceProfileIdentifier: string
  :param inferenceProfileIdentifier: **[REQUIRED]** 

    The ID or Amazon Resource Name (ARN) of the inference profile.

    

  
  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'inferenceProfileName': 'string',
          'description': 'string',
          'createdAt': datetime(2015, 1, 1),
          'updatedAt': datetime(2015, 1, 1),
          'inferenceProfileArn': 'string',
          'models': [
              {
                  'modelArn': 'string'
              },
          ],
          'inferenceProfileId': 'string',
          'status': 'ACTIVE',
          'type': 'SYSTEM_DEFINED'|'APPLICATION'
      }
      
    **Response Structure**

    

    - *(dict) --* 
      

      - **inferenceProfileName** *(string) --* 

        The name of the inference profile.

        
      

      - **description** *(string) --* 

        The description of the inference profile.

        
      

      - **createdAt** *(datetime) --* 

        The time at which the inference profile was created.

        
      

      - **updatedAt** *(datetime) --* 

        The time at which the inference profile was last updated.

        
      

      - **inferenceProfileArn** *(string) --* 

        The Amazon Resource Name (ARN) of the inference profile.

        
      

      - **models** *(list) --* 

        A list of information about each model in the inference profile.

        
        

        - *(dict) --* 

          Contains information about a model.

          
          

          - **modelArn** *(string) --* 

            The Amazon Resource Name (ARN) of the model.

            
      
    
      

      - **inferenceProfileId** *(string) --* 

        The unique identifier of the inference profile.

        
      

      - **status** *(string) --* 

        The status of the inference profile. ``ACTIVE`` means that the inference profile is ready to be used.

        
      

      - **type** *(string) --* 

        The type of the inference profile. The following types are possible:

         

        
        * ``SYSTEM_DEFINED`` – The inference profile is defined by Amazon Bedrock. You can route inference requests across regions with these inference profiles.
         
        * ``APPLICATION`` – The inference profile was created by a user. This type of inference profile can track metrics and costs when invoking the model in it. The inference profile may route requests to one or multiple regions.
        

        
  
  **Exceptions**
  
  *   :py:class:`Bedrock.Client.exceptions.ResourceNotFoundException`

  
  *   :py:class:`Bedrock.Client.exceptions.AccessDeniedException`

  
  *   :py:class:`Bedrock.Client.exceptions.ValidationException`

  
  *   :py:class:`Bedrock.Client.exceptions.InternalServerException`

  
  *   :py:class:`Bedrock.Client.exceptions.ThrottlingException`

  