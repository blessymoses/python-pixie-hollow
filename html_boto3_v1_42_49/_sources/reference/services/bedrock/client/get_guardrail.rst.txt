:doc:`Bedrock <../../bedrock>` / Client / get_guardrail

*************
get_guardrail
*************



.. py:method:: Bedrock.Client.get_guardrail(**kwargs)

  

  Gets details about a guardrail. If you don't specify a version, the response returns details for the ``DRAFT`` version.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/bedrock-2023-04-20/GetGuardrail>`_  


  **Request Syntax**
  ::

    response = client.get_guardrail(
        guardrailIdentifier='string',
        guardrailVersion='string'
    )
    
  :type guardrailIdentifier: string
  :param guardrailIdentifier: **[REQUIRED]** 

    The unique identifier of the guardrail for which to get details. This can be an ID or the ARN.

    

  
  :type guardrailVersion: string
  :param guardrailVersion: 

    The version of the guardrail for which to get details. If you don't specify a version, the response returns details for the ``DRAFT`` version.

    

  
  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'name': 'string',
          'description': 'string',
          'guardrailId': 'string',
          'guardrailArn': 'string',
          'version': 'string',
          'status': 'CREATING'|'UPDATING'|'VERSIONING'|'READY'|'FAILED'|'DELETING',
          'topicPolicy': {
              'topics': [
                  {
                      'name': 'string',
                      'definition': 'string',
                      'examples': [
                          'string',
                      ],
                      'type': 'DENY',
                      'inputAction': 'BLOCK'|'NONE',
                      'outputAction': 'BLOCK'|'NONE',
                      'inputEnabled': True|False,
                      'outputEnabled': True|False
                  },
              ],
              'tier': {
                  'tierName': 'CLASSIC'|'STANDARD'
              }
          },
          'contentPolicy': {
              'filters': [
                  {
                      'type': 'SEXUAL'|'VIOLENCE'|'HATE'|'INSULTS'|'MISCONDUCT'|'PROMPT_ATTACK',
                      'inputStrength': 'NONE'|'LOW'|'MEDIUM'|'HIGH',
                      'outputStrength': 'NONE'|'LOW'|'MEDIUM'|'HIGH',
                      'inputModalities': [
                          'TEXT'|'IMAGE',
                      ],
                      'outputModalities': [
                          'TEXT'|'IMAGE',
                      ],
                      'inputAction': 'BLOCK'|'NONE',
                      'outputAction': 'BLOCK'|'NONE',
                      'inputEnabled': True|False,
                      'outputEnabled': True|False
                  },
              ],
              'tier': {
                  'tierName': 'CLASSIC'|'STANDARD'
              }
          },
          'wordPolicy': {
              'words': [
                  {
                      'text': 'string',
                      'inputAction': 'BLOCK'|'NONE',
                      'outputAction': 'BLOCK'|'NONE',
                      'inputEnabled': True|False,
                      'outputEnabled': True|False
                  },
              ],
              'managedWordLists': [
                  {
                      'type': 'PROFANITY',
                      'inputAction': 'BLOCK'|'NONE',
                      'outputAction': 'BLOCK'|'NONE',
                      'inputEnabled': True|False,
                      'outputEnabled': True|False
                  },
              ]
          },
          'sensitiveInformationPolicy': {
              'piiEntities': [
                  {
                      'type': 'ADDRESS'|'AGE'|'AWS_ACCESS_KEY'|'AWS_SECRET_KEY'|'CA_HEALTH_NUMBER'|'CA_SOCIAL_INSURANCE_NUMBER'|'CREDIT_DEBIT_CARD_CVV'|'CREDIT_DEBIT_CARD_EXPIRY'|'CREDIT_DEBIT_CARD_NUMBER'|'DRIVER_ID'|'EMAIL'|'INTERNATIONAL_BANK_ACCOUNT_NUMBER'|'IP_ADDRESS'|'LICENSE_PLATE'|'MAC_ADDRESS'|'NAME'|'PASSWORD'|'PHONE'|'PIN'|'SWIFT_CODE'|'UK_NATIONAL_HEALTH_SERVICE_NUMBER'|'UK_NATIONAL_INSURANCE_NUMBER'|'UK_UNIQUE_TAXPAYER_REFERENCE_NUMBER'|'URL'|'USERNAME'|'US_BANK_ACCOUNT_NUMBER'|'US_BANK_ROUTING_NUMBER'|'US_INDIVIDUAL_TAX_IDENTIFICATION_NUMBER'|'US_PASSPORT_NUMBER'|'US_SOCIAL_SECURITY_NUMBER'|'VEHICLE_IDENTIFICATION_NUMBER',
                      'action': 'BLOCK'|'ANONYMIZE'|'NONE',
                      'inputAction': 'BLOCK'|'ANONYMIZE'|'NONE',
                      'outputAction': 'BLOCK'|'ANONYMIZE'|'NONE',
                      'inputEnabled': True|False,
                      'outputEnabled': True|False
                  },
              ],
              'regexes': [
                  {
                      'name': 'string',
                      'description': 'string',
                      'pattern': 'string',
                      'action': 'BLOCK'|'ANONYMIZE'|'NONE',
                      'inputAction': 'BLOCK'|'ANONYMIZE'|'NONE',
                      'outputAction': 'BLOCK'|'ANONYMIZE'|'NONE',
                      'inputEnabled': True|False,
                      'outputEnabled': True|False
                  },
              ]
          },
          'contextualGroundingPolicy': {
              'filters': [
                  {
                      'type': 'GROUNDING'|'RELEVANCE',
                      'threshold': 123.0,
                      'action': 'BLOCK'|'NONE',
                      'enabled': True|False
                  },
              ]
          },
          'automatedReasoningPolicy': {
              'policies': [
                  'string',
              ],
              'confidenceThreshold': 123.0
          },
          'crossRegionDetails': {
              'guardrailProfileId': 'string',
              'guardrailProfileArn': 'string'
          },
          'createdAt': datetime(2015, 1, 1),
          'updatedAt': datetime(2015, 1, 1),
          'statusReasons': [
              'string',
          ],
          'failureRecommendations': [
              'string',
          ],
          'blockedInputMessaging': 'string',
          'blockedOutputsMessaging': 'string',
          'kmsKeyArn': 'string'
      }
      
    **Response Structure**

    

    - *(dict) --* 
      

      - **name** *(string) --* 

        The name of the guardrail.

        
      

      - **description** *(string) --* 

        The description of the guardrail.

        
      

      - **guardrailId** *(string) --* 

        The unique identifier of the guardrail.

        
      

      - **guardrailArn** *(string) --* 

        The ARN of the guardrail.

        
      

      - **version** *(string) --* 

        The version of the guardrail.

        
      

      - **status** *(string) --* 

        The status of the guardrail.

        
      

      - **topicPolicy** *(dict) --* 

        The topic policy that was configured for the guardrail.

        
        

        - **topics** *(list) --* 

          A list of policies related to topics that the guardrail should deny.

          
          

          - *(dict) --* 

            Details about topics for the guardrail to identify and deny.

             

            This data type is used in the following API operations:

             

            
            * `GetGuardrail response body <https://docs.aws.amazon.com/bedrock/latest/APIReference/API_GetGuardrail.html#API_GetGuardrail_ResponseSyntax>`__
            

            
            

            - **name** *(string) --* 

              The name of the topic to deny.

              
            

            - **definition** *(string) --* 

              A definition of the topic to deny.

              
            

            - **examples** *(list) --* 

              A list of prompts, each of which is an example of a prompt that can be categorized as belonging to the topic.

              
              

              - *(string) --* 
          
            

            - **type** *(string) --* 

              Specifies to deny the topic.

              
            

            - **inputAction** *(string) --* 

              The action to take when harmful content is detected in the input. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **outputAction** *(string) --* 

              The action to take when harmful content is detected in the output. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **inputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the input. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
            

            - **outputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the output. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
        
      
        

        - **tier** *(dict) --* 

          The tier that your guardrail uses for denied topic filters.

          
          

          - **tierName** *(string) --* 

            The tier that your guardrail uses for denied topic filters. Valid values include:

             

            
            * ``CLASSIC`` tier – Provides established guardrails functionality supporting English, French, and Spanish languages.
             
            * ``STANDARD`` tier – Provides a more robust solution than the ``CLASSIC`` tier and has more comprehensive language support. This tier requires that your guardrail use `cross-Region inference <https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-cross-region.html>`__.
            

            
      
    
      

      - **contentPolicy** *(dict) --* 

        The content policy that was configured for the guardrail.

        
        

        - **filters** *(list) --* 

          Contains the type of the content filter and how strongly it should apply to prompts and model responses.

          
          

          - *(dict) --* 

            Contains filter strengths for harmful content. Guardrails support the following content filters to detect and filter harmful user inputs and FM-generated outputs.

             

            
            * **Hate** – Describes language or a statement that discriminates, criticizes, insults, denounces, or dehumanizes a person or group on the basis of an identity (such as race, ethnicity, gender, religion, sexual orientation, ability, and national origin).
             
            * **Insults** – Describes language or a statement that includes demeaning, humiliating, mocking, insulting, or belittling language. This type of language is also labeled as bullying.
             
            * **Sexual** – Describes language or a statement that indicates sexual interest, activity, or arousal using direct or indirect references to body parts, physical traits, or sex.
             
            * **Violence** – Describes language or a statement that includes glorification of or threats to inflict physical pain, hurt, or injury toward a person, group or thing.
            

             

            Content filtering depends on the confidence classification of user inputs and FM responses across each of the four harmful categories. All input and output statements are classified into one of four confidence levels (NONE, LOW, MEDIUM, HIGH) for each harmful category. For example, if a statement is classified as *Hate* with HIGH confidence, the likelihood of the statement representing hateful content is high. A single statement can be classified across multiple categories with varying confidence levels. For example, a single statement can be classified as *Hate* with HIGH confidence, *Insults* with LOW confidence, *Sexual* with NONE confidence, and *Violence* with MEDIUM confidence.

             

            For more information, see `Guardrails content filters <https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-filters.html>`__.

             

            This data type is used in the following API operations:

             

            
            * `GetGuardrail response body <https://docs.aws.amazon.com/bedrock/latest/APIReference/API_GetGuardrail.html#API_GetGuardrail_ResponseSyntax>`__
            

            
            

            - **type** *(string) --* 

              The harmful category that the content filter is applied to.

              
            

            - **inputStrength** *(string) --* 

              The strength of the content filter to apply to prompts. As you increase the filter strength, the likelihood of filtering harmful content increases and the probability of seeing harmful content in your application reduces.

              
            

            - **outputStrength** *(string) --* 

              The strength of the content filter to apply to model responses. As you increase the filter strength, the likelihood of filtering harmful content increases and the probability of seeing harmful content in your application reduces.

              
            

            - **inputModalities** *(list) --* 

              The input modalities selected for the guardrail content filter.

              
              

              - *(string) --* 
          
            

            - **outputModalities** *(list) --* 

              The output modalities selected for the guardrail content filter.

              
              

              - *(string) --* 
          
            

            - **inputAction** *(string) --* 

              The action to take when harmful content is detected in the input. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **outputAction** *(string) --* 

              The action to take when harmful content is detected in the output. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **inputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the input. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
            

            - **outputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the output. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
        
      
        

        - **tier** *(dict) --* 

          The tier that your guardrail uses for content filters.

          
          

          - **tierName** *(string) --* 

            The tier that your guardrail uses for content filters. Valid values include:

             

            
            * ``CLASSIC`` tier – Provides established guardrails functionality supporting English, French, and Spanish languages.
             
            * ``STANDARD`` tier – Provides a more robust solution than the ``CLASSIC`` tier and has more comprehensive language support. This tier requires that your guardrail use `cross-Region inference <https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-cross-region.html>`__.
            

            
      
    
      

      - **wordPolicy** *(dict) --* 

        The word policy that was configured for the guardrail.

        
        

        - **words** *(list) --* 

          A list of words configured for the guardrail.

          
          

          - *(dict) --* 

            A word configured for the guardrail.

            
            

            - **text** *(string) --* 

              Text of the word configured for the guardrail to block.

              
            

            - **inputAction** *(string) --* 

              The action to take when harmful content is detected in the input. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **outputAction** *(string) --* 

              The action to take when harmful content is detected in the output. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **inputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the input. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
            

            - **outputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the output. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
        
      
        

        - **managedWordLists** *(list) --* 

          A list of managed words configured for the guardrail.

          
          

          - *(dict) --* 

            The managed word list that was configured for the guardrail. (This is a list of words that are pre-defined and managed by guardrails only.)

            
            

            - **type** *(string) --* 

              ManagedWords$type The managed word type that was configured for the guardrail. (For now, we only offer profanity word list)

              
            

            - **inputAction** *(string) --* 

              The action to take when harmful content is detected in the input. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **outputAction** *(string) --* 

              The action to take when harmful content is detected in the output. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **inputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the input. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
            

            - **outputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the output. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
        
      
    
      

      - **sensitiveInformationPolicy** *(dict) --* 

        The sensitive information policy that was configured for the guardrail.

        
        

        - **piiEntities** *(list) --* 

          The list of PII entities configured for the guardrail.

          
          

          - *(dict) --* 

            The PII entity configured for the guardrail.

            
            

            - **type** *(string) --* 

              The type of PII entity. For example, Social Security Number.

              
            

            - **action** *(string) --* 

              The configured guardrail action when PII entity is detected.

              
            

            - **inputAction** *(string) --* 

              The action to take when harmful content is detected in the input. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``ANONYMIZE`` – Mask the content and replace it with identifier tags.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **outputAction** *(string) --* 

              The action to take when harmful content is detected in the output. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``ANONYMIZE`` – Mask the content and replace it with identifier tags.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **inputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the input. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
            

            - **outputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the output. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
        
      
        

        - **regexes** *(list) --* 

          The list of regular expressions configured for the guardrail.

          
          

          - *(dict) --* 

            The regular expression configured for the guardrail.

            
            

            - **name** *(string) --* 

              The name of the regular expression for the guardrail.

              
            

            - **description** *(string) --* 

              The description of the regular expression for the guardrail.

              
            

            - **pattern** *(string) --* 

              The pattern of the regular expression configured for the guardrail.

              
            

            - **action** *(string) --* 

              The action taken when a match to the regular expression is detected.

              
            

            - **inputAction** *(string) --* 

              The action to take when harmful content is detected in the input. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **outputAction** *(string) --* 

              The action to take when harmful content is detected in the output. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **inputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the input. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
            

            - **outputEnabled** *(boolean) --* 

              Indicates whether guardrail evaluation is enabled on the output. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
        
      
    
      

      - **contextualGroundingPolicy** *(dict) --* 

        The contextual grounding policy used in the guardrail.

        
        

        - **filters** *(list) --* 

          The filter details for the guardrails contextual grounding policy.

          
          

          - *(dict) --* 

            The details for the guardrails contextual grounding filter.

            
            

            - **type** *(string) --* 

              The filter type details for the guardrails contextual grounding filter.

              
            

            - **threshold** *(float) --* 

              The threshold details for the guardrails contextual grounding filter.

              
            

            - **action** *(string) --* 

              The action to take when content fails the contextual grounding evaluation. Supported values include:

               

              
              * ``BLOCK`` – Block the content and replace it with blocked messaging.
               
              * ``NONE`` – Take no action but return detection information in the trace response.
              

              
            

            - **enabled** *(boolean) --* 

              Indicates whether contextual grounding is enabled for evaluation. When disabled, you aren't charged for the evaluation. The evaluation doesn't appear in the response.

              
        
      
    
      

      - **automatedReasoningPolicy** *(dict) --* 

        The current Automated Reasoning policy configuration for the guardrail, if any is configured.

        
        

        - **policies** *(list) --* 

          The list of Automated Reasoning policy ARNs that should be applied as part of this guardrail configuration.

          
          

          - *(string) --* 
      
        

        - **confidenceThreshold** *(float) --* 

          The minimum confidence level required for Automated Reasoning policy violations to trigger guardrail actions. Values range from 0.0 to 1.0.

          
    
      

      - **crossRegionDetails** *(dict) --* 

        Details about the system-defined guardrail profile that you're using with your guardrail, including the guardrail profile ID and Amazon Resource Name (ARN).

        
        

        - **guardrailProfileId** *(string) --* 

          The ID of the guardrail profile that your guardrail is using. Profile availability depends on your current Amazon Web Services Region. For more information, see the `Amazon Bedrock User Guide <https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-cross-region-support.html>`__.

          
        

        - **guardrailProfileArn** *(string) --* 

          The Amazon Resource Name (ARN) of the guardrail profile that you're using with your guardrail.

          
    
      

      - **createdAt** *(datetime) --* 

        The date and time at which the guardrail was created.

        
      

      - **updatedAt** *(datetime) --* 

        The date and time at which the guardrail was updated.

        
      

      - **statusReasons** *(list) --* 

        Appears if the ``status`` is ``FAILED``. A list of reasons for why the guardrail failed to be created, updated, versioned, or deleted.

        
        

        - *(string) --* 
    
      

      - **failureRecommendations** *(list) --* 

        Appears if the ``status`` of the guardrail is ``FAILED``. A list of recommendations to carry out before retrying the request.

        
        

        - *(string) --* 
    
      

      - **blockedInputMessaging** *(string) --* 

        The message that the guardrail returns when it blocks a prompt.

        
      

      - **blockedOutputsMessaging** *(string) --* 

        The message that the guardrail returns when it blocks a model response.

        
      

      - **kmsKeyArn** *(string) --* 

        The ARN of the KMS key that encrypts the guardrail.

        
  
  **Exceptions**
  
  *   :py:class:`Bedrock.Client.exceptions.ResourceNotFoundException`

  
  *   :py:class:`Bedrock.Client.exceptions.AccessDeniedException`

  
  *   :py:class:`Bedrock.Client.exceptions.ValidationException`

  
  *   :py:class:`Bedrock.Client.exceptions.InternalServerException`

  
  *   :py:class:`Bedrock.Client.exceptions.ThrottlingException`

  