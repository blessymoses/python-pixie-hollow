:doc:`MachineLearning <../../machinelearning>` / Client / create_batch_prediction

***********************
create_batch_prediction
***********************



.. py:method:: MachineLearning.Client.create_batch_prediction(**kwargs)

  

  Generates predictions for a group of observations. The observations to process exist in one or more data files referenced by a ``DataSource``. This operation creates a new ``BatchPrediction``, and uses an ``MLModel`` and the data files referenced by the ``DataSource`` as information sources.

   

  ``CreateBatchPrediction`` is an asynchronous operation. In response to ``CreateBatchPrediction``, Amazon Machine Learning (Amazon ML) immediately returns and sets the ``BatchPrediction`` status to ``PENDING``. After the ``BatchPrediction`` completes, Amazon ML sets the status to ``COMPLETED``.

   

  You can poll for status updates by using the  GetBatchPrediction operation and checking the ``Status`` parameter of the result. After the ``COMPLETED`` status appears, the results are available in the location specified by the ``OutputUri`` parameter.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/machinelearning-2014-12-12/CreateBatchPrediction>`_  


  **Request Syntax**
  ::

    response = client.create_batch_prediction(
        BatchPredictionId='string',
        BatchPredictionName='string',
        MLModelId='string',
        BatchPredictionDataSourceId='string',
        OutputUri='string'
    )
    
  :type BatchPredictionId: string
  :param BatchPredictionId: **[REQUIRED]** 

    A user-supplied ID that uniquely identifies the ``BatchPrediction``.

    

  
  :type BatchPredictionName: string
  :param BatchPredictionName: 

    A user-supplied name or description of the ``BatchPrediction``. ``BatchPredictionName`` can only use the UTF-8 character set.

    

  
  :type MLModelId: string
  :param MLModelId: **[REQUIRED]** 

    The ID of the ``MLModel`` that will generate predictions for the group of observations.

    

  
  :type BatchPredictionDataSourceId: string
  :param BatchPredictionDataSourceId: **[REQUIRED]** 

    The ID of the ``DataSource`` that points to the group of observations to predict.

    

  
  :type OutputUri: string
  :param OutputUri: **[REQUIRED]** 

    The location of an Amazon Simple Storage Service (Amazon S3) bucket or directory to store the batch prediction results. The following substrings are not allowed in the ``s3 key`` portion of the ``outputURI`` field: ':', '//', '/./', '/../'.

     

    Amazon ML needs permissions to store and retrieve the logs on your behalf. For information about how to set permissions, see the `Amazon Machine Learning Developer Guide <https://docs.aws.amazon.com/machine-learning/latest/dg>`__.

    

  
  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'BatchPredictionId': 'string'
      }
      
    **Response Structure**

    

    - *(dict) --* 

      Represents the output of a ``CreateBatchPrediction`` operation, and is an acknowledgement that Amazon ML received the request.

       

      The ``CreateBatchPrediction`` operation is asynchronous. You can poll for status updates by using the ``>GetBatchPrediction`` operation and checking the ``Status`` parameter of the result.

      
      

      - **BatchPredictionId** *(string) --* 

        A user-supplied ID that uniquely identifies the ``BatchPrediction``. This value is identical to the value of the ``BatchPredictionId`` in the request.

        
  
  **Exceptions**
  
  *   :py:class:`MachineLearning.Client.exceptions.InvalidInputException`

  
  *   :py:class:`MachineLearning.Client.exceptions.InternalServerException`

  
  *   :py:class:`MachineLearning.Client.exceptions.IdempotentParameterMismatchException`

  