:doc:`MachineLearning <../../machinelearning>` / Client / get_evaluation

**************
get_evaluation
**************



.. py:method:: MachineLearning.Client.get_evaluation(**kwargs)

  

  Returns an ``Evaluation`` that includes metadata as well as the current status of the ``Evaluation``.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/machinelearning-2014-12-12/GetEvaluation>`_  


  **Request Syntax**
  ::

    response = client.get_evaluation(
        EvaluationId='string'
    )
    
  :type EvaluationId: string
  :param EvaluationId: **[REQUIRED]** 

    The ID of the ``Evaluation`` to retrieve. The evaluation of each ``MLModel`` is recorded and cataloged. The ID provides the means to access the information.

    

  
  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'EvaluationId': 'string',
          'MLModelId': 'string',
          'EvaluationDataSourceId': 'string',
          'InputDataLocationS3': 'string',
          'CreatedByIamUser': 'string',
          'CreatedAt': datetime(2015, 1, 1),
          'LastUpdatedAt': datetime(2015, 1, 1),
          'Name': 'string',
          'Status': 'PENDING'|'INPROGRESS'|'FAILED'|'COMPLETED'|'DELETED',
          'PerformanceMetrics': {
              'Properties': {
                  'string': 'string'
              }
          },
          'LogUri': 'string',
          'Message': 'string',
          'ComputeTime': 123,
          'FinishedAt': datetime(2015, 1, 1),
          'StartedAt': datetime(2015, 1, 1)
      }
      
    **Response Structure**

    

    - *(dict) --* 

      Represents the output of a ``GetEvaluation`` operation and describes an ``Evaluation``.

      
      

      - **EvaluationId** *(string) --* 

        The evaluation ID which is same as the ``EvaluationId`` in the request.

        
      

      - **MLModelId** *(string) --* 

        The ID of the ``MLModel`` that was the focus of the evaluation.

        
      

      - **EvaluationDataSourceId** *(string) --* 

        The ``DataSource`` used for this evaluation.

        
      

      - **InputDataLocationS3** *(string) --* 

        The location of the data file or directory in Amazon Simple Storage Service (Amazon S3).

        
      

      - **CreatedByIamUser** *(string) --* 

        The AWS user account that invoked the evaluation. The account type can be either an AWS root account or an AWS Identity and Access Management (IAM) user account.

        
      

      - **CreatedAt** *(datetime) --* 

        The time that the ``Evaluation`` was created. The time is expressed in epoch time.

        
      

      - **LastUpdatedAt** *(datetime) --* 

        The time of the most recent edit to the ``Evaluation``. The time is expressed in epoch time.

        
      

      - **Name** *(string) --* 

        A user-supplied name or description of the ``Evaluation``.

        
      

      - **Status** *(string) --* 

        The status of the evaluation. This element can have one of the following values:

         

        
        * ``PENDING`` - Amazon Machine Language (Amazon ML) submitted a request to evaluate an ``MLModel``.
         
        * ``INPROGRESS`` - The evaluation is underway.
         
        * ``FAILED`` - The request to evaluate an ``MLModel`` did not run to completion. It is not usable.
         
        * ``COMPLETED`` - The evaluation process completed successfully.
         
        * ``DELETED`` - The ``Evaluation`` is marked as deleted. It is not usable.
        

        
      

      - **PerformanceMetrics** *(dict) --* 

        Measurements of how well the ``MLModel`` performed using observations referenced by the ``DataSource``. One of the following metric is returned based on the type of the ``MLModel``:

         

        
        * BinaryAUC: A binary ``MLModel`` uses the Area Under the Curve (AUC) technique to measure performance.
         
        * RegressionRMSE: A regression ``MLModel`` uses the Root Mean Square Error (RMSE) technique to measure performance. RMSE measures the difference between predicted and actual values for a single variable.
         
        * MulticlassAvgFScore: A multiclass ``MLModel`` uses the F1 score technique to measure performance.
        

         

        For more information about performance metrics, please see the `Amazon Machine Learning Developer Guide <https://docs.aws.amazon.com/machine-learning/latest/dg>`__.

        
        

        - **Properties** *(dict) --* 
          

          - *(string) --* 
            

            - *(string) --* 
      
    
    
      

      - **LogUri** *(string) --* 

        A link to the file that contains logs of the ``CreateEvaluation`` operation.

        
      

      - **Message** *(string) --* 

        A description of the most recent details about evaluating the ``MLModel``.

        
      

      - **ComputeTime** *(integer) --* 

        The approximate CPU time in milliseconds that Amazon Machine Learning spent processing the ``Evaluation``, normalized and scaled on computation resources. ``ComputeTime`` is only available if the ``Evaluation`` is in the ``COMPLETED`` state.

        
      

      - **FinishedAt** *(datetime) --* 

        The epoch time when Amazon Machine Learning marked the ``Evaluation`` as ``COMPLETED`` or ``FAILED``. ``FinishedAt`` is only available when the ``Evaluation`` is in the ``COMPLETED`` or ``FAILED`` state.

        
      

      - **StartedAt** *(datetime) --* 

        The epoch time when Amazon Machine Learning marked the ``Evaluation`` as ``INPROGRESS``. ``StartedAt`` isn't available if the ``Evaluation`` is in the ``PENDING`` state.

        
  
  **Exceptions**
  
  *   :py:class:`MachineLearning.Client.exceptions.InvalidInputException`

  
  *   :py:class:`MachineLearning.Client.exceptions.ResourceNotFoundException`

  
  *   :py:class:`MachineLearning.Client.exceptions.InternalServerException`

  