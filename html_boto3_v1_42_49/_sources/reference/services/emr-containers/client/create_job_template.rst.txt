:doc:`EMRContainers <../../emr-containers>` / Client / create_job_template

*******************
create_job_template
*******************



.. py:method:: EMRContainers.Client.create_job_template(**kwargs)

  

  Creates a job template. Job template stores values of StartJobRun API request in a template and can be used to start a job run. Job template allows two use cases: avoid repeating recurring StartJobRun API request values, enforcing certain values in StartJobRun API request.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/emr-containers-2020-10-01/CreateJobTemplate>`_  


  **Request Syntax**
  ::

    response = client.create_job_template(
        name='string',
        clientToken='string',
        jobTemplateData={
            'executionRoleArn': 'string',
            'releaseLabel': 'string',
            'configurationOverrides': {
                'applicationConfiguration': [
                    {
                        'classification': 'string',
                        'properties': {
                            'string': 'string'
                        },
                        'configurations': {'... recursive ...'}
                    },
                ],
                'monitoringConfiguration': {
                    'persistentAppUI': 'string',
                    'cloudWatchMonitoringConfiguration': {
                        'logGroupName': 'string',
                        'logStreamNamePrefix': 'string'
                    },
                    's3MonitoringConfiguration': {
                        'logUri': 'string'
                    }
                }
            },
            'jobDriver': {
                'sparkSubmitJobDriver': {
                    'entryPoint': 'string',
                    'entryPointArguments': [
                        'string',
                    ],
                    'sparkSubmitParameters': 'string'
                },
                'sparkSqlJobDriver': {
                    'entryPoint': 'string',
                    'sparkSqlParameters': 'string'
                }
            },
            'parameterConfiguration': {
                'string': {
                    'type': 'NUMBER'|'STRING',
                    'defaultValue': 'string'
                }
            },
            'jobTags': {
                'string': 'string'
            }
        },
        tags={
            'string': 'string'
        },
        kmsKeyArn='string'
    )
    
  :type name: string
  :param name: **[REQUIRED]** 

    The specified name of the job template.

    

  
  :type clientToken: string
  :param clientToken: **[REQUIRED]** 

    The client token of the job template.

    This field is autopopulated if not provided.

  
  :type jobTemplateData: dict
  :param jobTemplateData: **[REQUIRED]** 

    The job template data which holds values of StartJobRun API request.

    

  
    - **executionRoleArn** *(string) --* **[REQUIRED]** 

      The execution role ARN of the job run.

      

    
    - **releaseLabel** *(string) --* **[REQUIRED]** 

      The release version of Amazon EMR.

      

    
    - **configurationOverrides** *(dict) --* 

      The configuration settings that are used to override defaults configuration.

      

    
      - **applicationConfiguration** *(list) --* 

        The configurations for the application running by the job run.

        

      
        - *(dict) --* 

          A configuration specification to be used when provisioning virtual clusters, which can include configurations for applications and software bundled with Amazon EMR on EKS. A configuration consists of a classification, properties, and optional nested configurations. A classification refers to an application-specific configuration file. Properties are the settings you want to change in that file.

          

        
          - **classification** *(string) --* **[REQUIRED]** 

            The classification within a configuration.

            

          
          - **properties** *(dict) --* 

            A set of properties specified within a configuration classification.

            

          
            - *(string) --* 

            
              - *(string) --* 

              
        
      
          - **configurations** *(list) --* 

            A list of additional configurations to apply within a configuration object.

            

          
        
    
      - **monitoringConfiguration** *(dict) --* 

        The configurations for monitoring.

        

      
        - **persistentAppUI** *(string) --* 

          Monitoring configurations for the persistent application UI.

          

        
        - **cloudWatchMonitoringConfiguration** *(dict) --* 

          Monitoring configurations for CloudWatch.

          

        
          - **logGroupName** *(string) --* 

            The name of the log group for log publishing.

            

          
          - **logStreamNamePrefix** *(string) --* 

            The specified name prefix for log streams.

            

          
        
        - **s3MonitoringConfiguration** *(dict) --* 

          Amazon S3 configuration for monitoring log publishing.

          

        
          - **logUri** *(string) --* 

            Amazon S3 destination URI for log publishing.

            

          
        
      
    
    - **jobDriver** *(dict) --* **[REQUIRED]** 

      Specify the driver that the job runs on. Exactly one of the two available job drivers is required, either sparkSqlJobDriver or sparkSubmitJobDriver.

      

    
      - **sparkSubmitJobDriver** *(dict) --* 

        The job driver parameters specified for spark submit.

        

      
        - **entryPoint** *(string) --* **[REQUIRED]** 

          The entry point of job application.

          

        
        - **entryPointArguments** *(list) --* 

          The arguments for job application.

          

        
          - *(string) --* 

          
      
        - **sparkSubmitParameters** *(string) --* 

          The Spark submit parameters that are used for job runs.

          

        
      
      - **sparkSqlJobDriver** *(dict) --* 

        The job driver for job type.

        

      
        - **entryPoint** *(string) --* 

          The SQL file to be executed.

          

        
        - **sparkSqlParameters** *(string) --* 

          The Spark parameters to be included in the Spark SQL command.

          

        
      
    
    - **parameterConfiguration** *(dict) --* 

      The configuration of parameters existing in the job template.

      

    
      - *(string) --* 

      
        - *(dict) --* 

          The configuration of a job template parameter.

          

        
          - **type** *(string) --* 

            The type of the job template parameter. Allowed values are: ‘STRING’, ‘NUMBER’.

            

          
          - **defaultValue** *(string) --* 

            The default value for the job template parameter.

            

          
        
  

    - **jobTags** *(dict) --* 

      The tags assigned to jobs started using the job template.

      

    
      - *(string) --* 

      
        - *(string) --* 

        
  

  
  :type tags: dict
  :param tags: 

    The tags that are associated with the job template.

    

  
    - *(string) --* 

    
      - *(string) --* 

      


  :type kmsKeyArn: string
  :param kmsKeyArn: 

    The KMS key ARN used to encrypt the job template.

    

  
  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'id': 'string',
          'name': 'string',
          'arn': 'string',
          'createdAt': datetime(2015, 1, 1)
      }
      
    **Response Structure**

    

    - *(dict) --* 
      

      - **id** *(string) --* 

        This output display the created job template ID.

        
      

      - **name** *(string) --* 

        This output displays the name of the created job template.

        
      

      - **arn** *(string) --* 

        This output display the ARN of the created job template.

        
      

      - **createdAt** *(datetime) --* 

        This output displays the date and time when the job template was created.

        
  
  **Exceptions**
  
  *   :py:class:`EMRContainers.Client.exceptions.ValidationException`

  
  *   :py:class:`EMRContainers.Client.exceptions.ResourceNotFoundException`

  
  *   :py:class:`EMRContainers.Client.exceptions.InternalServerException`

  