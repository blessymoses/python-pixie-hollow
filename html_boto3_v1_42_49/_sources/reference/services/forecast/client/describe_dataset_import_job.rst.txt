:doc:`ForecastService <../../forecast>` / Client / describe_dataset_import_job

***************************
describe_dataset_import_job
***************************



.. py:method:: ForecastService.Client.describe_dataset_import_job(**kwargs)

  

  Describes a dataset import job created using the `CreateDatasetImportJob <https://docs.aws.amazon.com/forecast/latest/dg/API_CreateDatasetImportJob.html>`__ operation.

   

  In addition to listing the parameters provided in the ``CreateDatasetImportJob`` request, this operation includes the following properties:

   

  
  * ``CreationTime``
   
  * ``LastModificationTime``
   
  * ``DataSize``
   
  * ``FieldStatistics``
   
  * ``Status``
   
  * ``Message`` - If an error occurred, information about the error.
  

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/forecast-2018-06-26/DescribeDatasetImportJob>`_  


  **Request Syntax**
  ::

    response = client.describe_dataset_import_job(
        DatasetImportJobArn='string'
    )
    
  :type DatasetImportJobArn: string
  :param DatasetImportJobArn: **[REQUIRED]** 

    The Amazon Resource Name (ARN) of the dataset import job.

    

  
  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'DatasetImportJobName': 'string',
          'DatasetImportJobArn': 'string',
          'DatasetArn': 'string',
          'TimestampFormat': 'string',
          'TimeZone': 'string',
          'UseGeolocationForTimeZone': True|False,
          'GeolocationFormat': 'string',
          'DataSource': {
              'S3Config': {
                  'Path': 'string',
                  'RoleArn': 'string',
                  'KMSKeyArn': 'string'
              }
          },
          'EstimatedTimeRemainingInMinutes': 123,
          'FieldStatistics': {
              'string': {
                  'Count': 123,
                  'CountDistinct': 123,
                  'CountNull': 123,
                  'CountNan': 123,
                  'Min': 'string',
                  'Max': 'string',
                  'Avg': 123.0,
                  'Stddev': 123.0,
                  'CountLong': 123,
                  'CountDistinctLong': 123,
                  'CountNullLong': 123,
                  'CountNanLong': 123
              }
          },
          'DataSize': 123.0,
          'Status': 'string',
          'Message': 'string',
          'CreationTime': datetime(2015, 1, 1),
          'LastModificationTime': datetime(2015, 1, 1),
          'Format': 'string',
          'ImportMode': 'FULL'|'INCREMENTAL'
      }
      
    **Response Structure**

    

    - *(dict) --* 
      

      - **DatasetImportJobName** *(string) --* 

        The name of the dataset import job.

        
      

      - **DatasetImportJobArn** *(string) --* 

        The ARN of the dataset import job.

        
      

      - **DatasetArn** *(string) --* 

        The Amazon Resource Name (ARN) of the dataset that the training data was imported to.

        
      

      - **TimestampFormat** *(string) --* 

        The format of timestamps in the dataset. The format that you specify depends on the ``DataFrequency`` specified when the dataset was created. The following formats are supported

         

        
        * "yyyy-MM-dd" For the following data frequencies: Y, M, W, and D
         
        * "yyyy-MM-dd HH:mm:ss" For the following data frequencies: H, 30min, 15min, and 1min; and optionally, for: Y, M, W, and D
        

        
      

      - **TimeZone** *(string) --* 

        The single time zone applied to every item in the dataset

        
      

      - **UseGeolocationForTimeZone** *(boolean) --* 

        Whether ``TimeZone`` is automatically derived from the geolocation attribute.

        
      

      - **GeolocationFormat** *(string) --* 

        The format of the geolocation attribute. Valid Values: ``"LAT_LONG"`` and ``"CC_POSTALCODE"``.

        
      

      - **DataSource** *(dict) --* 

        The location of the training data to import and an Identity and Access Management (IAM) role that Amazon Forecast can assume to access the data.

         

        If encryption is used, ``DataSource`` includes an Key Management Service (KMS) key.

        
        

        - **S3Config** *(dict) --* 

          The path to the data stored in an Amazon Simple Storage Service (Amazon S3) bucket along with the credentials to access the data.

          
          

          - **Path** *(string) --* 

            The path to an Amazon Simple Storage Service (Amazon S3) bucket or file(s) in an Amazon S3 bucket.

            
          

          - **RoleArn** *(string) --* 

            The ARN of the Identity and Access Management (IAM) role that Amazon Forecast can assume to access the Amazon S3 bucket or files. If you provide a value for the ``KMSKeyArn`` key, the role must allow access to the key.

             

            Passing a role across Amazon Web Services accounts is not allowed. If you pass a role that isn't in your account, you get an ``InvalidInputException`` error.

            
          

          - **KMSKeyArn** *(string) --* 

            The Amazon Resource Name (ARN) of an Key Management Service (KMS) key.

            
      
    
      

      - **EstimatedTimeRemainingInMinutes** *(integer) --* 

        The estimated time remaining in minutes for the dataset import job to complete.

        
      

      - **FieldStatistics** *(dict) --* 

        Statistical information about each field in the input data.

        
        

        - *(string) --* 
          

          - *(dict) --* 

            Provides statistics for each data field imported into to an Amazon Forecast dataset with the `CreateDatasetImportJob <https://docs.aws.amazon.com/forecast/latest/dg/API_CreateDatasetImportJob.html>`__ operation.

            
            

            - **Count** *(integer) --* 

              The number of values in the field. If the response value is -1, refer to ``CountLong``.

              
            

            - **CountDistinct** *(integer) --* 

              The number of distinct values in the field. If the response value is -1, refer to ``CountDistinctLong``.

              
            

            - **CountNull** *(integer) --* 

              The number of null values in the field. If the response value is -1, refer to ``CountNullLong``.

              
            

            - **CountNan** *(integer) --* 

              The number of NAN (not a number) values in the field. If the response value is -1, refer to ``CountNanLong``.

              
            

            - **Min** *(string) --* 

              For a numeric field, the minimum value in the field.

              
            

            - **Max** *(string) --* 

              For a numeric field, the maximum value in the field.

              
            

            - **Avg** *(float) --* 

              For a numeric field, the average value in the field.

              
            

            - **Stddev** *(float) --* 

              For a numeric field, the standard deviation.

              
            

            - **CountLong** *(integer) --* 

              The number of values in the field. ``CountLong`` is used instead of ``Count`` if the value is greater than 2,147,483,647.

              
            

            - **CountDistinctLong** *(integer) --* 

              The number of distinct values in the field. ``CountDistinctLong`` is used instead of ``CountDistinct`` if the value is greater than 2,147,483,647.

              
            

            - **CountNullLong** *(integer) --* 

              The number of null values in the field. ``CountNullLong`` is used instead of ``CountNull`` if the value is greater than 2,147,483,647.

              
            

            - **CountNanLong** *(integer) --* 

              The number of NAN (not a number) values in the field. ``CountNanLong`` is used instead of ``CountNan`` if the value is greater than 2,147,483,647.

              
        
    
  
      

      - **DataSize** *(float) --* 

        The size of the dataset in gigabytes (GB) after the import job has finished.

        
      

      - **Status** *(string) --* 

        The status of the dataset import job. States include:

         

        
        * ``ACTIVE``
         
        * ``CREATE_PENDING``, ``CREATE_IN_PROGRESS``, ``CREATE_FAILED``
         
        * ``DELETE_PENDING``, ``DELETE_IN_PROGRESS``, ``DELETE_FAILED``
         
        * ``CREATE_STOPPING``, ``CREATE_STOPPED``
        

        
      

      - **Message** *(string) --* 

        If an error occurred, an informational message about the error.

        
      

      - **CreationTime** *(datetime) --* 

        When the dataset import job was created.

        
      

      - **LastModificationTime** *(datetime) --* 

        The last time the resource was modified. The timestamp depends on the status of the job:

         

        
        * ``CREATE_PENDING`` - The ``CreationTime``.
         
        * ``CREATE_IN_PROGRESS`` - The current timestamp.
         
        * ``CREATE_STOPPING`` - The current timestamp.
         
        * ``CREATE_STOPPED`` - When the job stopped.
         
        * ``ACTIVE`` or ``CREATE_FAILED`` - When the job finished or failed.
        

        
      

      - **Format** *(string) --* 

        The format of the imported data, CSV or PARQUET.

        
      

      - **ImportMode** *(string) --* 

        The import mode of the dataset import job, FULL or INCREMENTAL.

        
  
  **Exceptions**
  
  *   :py:class:`ForecastService.Client.exceptions.InvalidInputException`

  
  *   :py:class:`ForecastService.Client.exceptions.ResourceNotFoundException`

  