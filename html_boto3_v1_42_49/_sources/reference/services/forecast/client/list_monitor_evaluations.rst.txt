:doc:`ForecastService <../../forecast>` / Client / list_monitor_evaluations

************************
list_monitor_evaluations
************************



.. py:method:: ForecastService.Client.list_monitor_evaluations(**kwargs)

  

  Returns a list of the monitoring evaluation results and predictor events collected by the monitor resource during different windows of time.

   

  For information about monitoring see  predictor-monitoring. For more information about retrieving monitoring results see `Viewing Monitoring Results <https://docs.aws.amazon.com/forecast/latest/dg/predictor-monitoring-results.html>`__.

  

  See also: `AWS API Documentation <https://docs.aws.amazon.com/goto/WebAPI/forecast-2018-06-26/ListMonitorEvaluations>`_  


  **Request Syntax**
  ::

    response = client.list_monitor_evaluations(
        NextToken='string',
        MaxResults=123,
        MonitorArn='string',
        Filters=[
            {
                'Key': 'string',
                'Value': 'string',
                'Condition': 'IS'|'IS_NOT'
            },
        ]
    )
    
  :type NextToken: string
  :param NextToken: 

    If the result of the previous request was truncated, the response includes a ``NextToken``. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.

    

  
  :type MaxResults: integer
  :param MaxResults: 

    The maximum number of monitoring results to return.

    

  
  :type MonitorArn: string
  :param MonitorArn: **[REQUIRED]** 

    The Amazon Resource Name (ARN) of the monitor resource to get results from.

    

  
  :type Filters: list
  :param Filters: 

    An array of filters. For each filter, provide a condition and a match statement. The condition is either ``IS`` or ``IS_NOT``, which specifies whether to include or exclude the resources that match the statement from the list. The match statement consists of a key and a value.

     

    **Filter properties**

     

    
    * ``Condition`` - The condition to apply. Valid values are ``IS`` and ``IS_NOT``.
     
    * ``Key`` - The name of the parameter to filter on. The only valid value is ``EvaluationState``.
     
    * ``Value`` - The value to match. Valid values are only ``SUCCESS`` or ``FAILURE``.
    

     

    For example, to list only successful monitor evaluations, you would specify:

     

    ``"Filters": [ { "Condition": "IS", "Key": "EvaluationState", "Value": "SUCCESS" } ]``

    

  
    - *(dict) --* 

      Describes a filter for choosing a subset of objects. Each filter consists of a condition and a match statement. The condition is either ``IS`` or ``IS_NOT``, which specifies whether to include or exclude the objects that match the statement, respectively. The match statement consists of a key and a value.

      

    
      - **Key** *(string) --* **[REQUIRED]** 

        The name of the parameter to filter on.

        

      
      - **Value** *(string) --* **[REQUIRED]** 

        The value to match.

        

      
      - **Condition** *(string) --* **[REQUIRED]** 

        The condition to apply. To include the objects that match the statement, specify ``IS``. To exclude matching objects, specify ``IS_NOT``.

        

      
    

  
  :rtype: dict
  :returns: 
    
    **Response Syntax**

    
    ::

      {
          'NextToken': 'string',
          'PredictorMonitorEvaluations': [
              {
                  'ResourceArn': 'string',
                  'MonitorArn': 'string',
                  'EvaluationTime': datetime(2015, 1, 1),
                  'EvaluationState': 'string',
                  'WindowStartDatetime': datetime(2015, 1, 1),
                  'WindowEndDatetime': datetime(2015, 1, 1),
                  'PredictorEvent': {
                      'Detail': 'string',
                      'Datetime': datetime(2015, 1, 1)
                  },
                  'MonitorDataSource': {
                      'DatasetImportJobArn': 'string',
                      'ForecastArn': 'string',
                      'PredictorArn': 'string'
                  },
                  'MetricResults': [
                      {
                          'MetricName': 'string',
                          'MetricValue': 123.0
                      },
                  ],
                  'NumItemsEvaluated': 123,
                  'Message': 'string'
              },
          ]
      }
      
    **Response Structure**

    

    - *(dict) --* 
      

      - **NextToken** *(string) --* 

        If the response is truncated, Amazon Forecast returns this token. To retrieve the next set of results, use the token in the next request. Tokens expire after 24 hours.

        
      

      - **PredictorMonitorEvaluations** *(list) --* 

        The monitoring results and predictor events collected by the monitor resource during different windows of time.

         

        For information about monitoring see `Viewing Monitoring Results <https://docs.aws.amazon.com/forecast/latest/dg/predictor-monitoring-results.html>`__. For more information about retrieving monitoring results see `Viewing Monitoring Results <https://docs.aws.amazon.com/forecast/latest/dg/predictor-monitoring-results.html>`__.

        
        

        - *(dict) --* 

          Describes the results of a monitor evaluation.

          
          

          - **ResourceArn** *(string) --* 

            The Amazon Resource Name (ARN) of the resource to monitor.

            
          

          - **MonitorArn** *(string) --* 

            The Amazon Resource Name (ARN) of the monitor resource.

            
          

          - **EvaluationTime** *(datetime) --* 

            The timestamp that indicates when the monitor evaluation was started.

            
          

          - **EvaluationState** *(string) --* 

            The status of the monitor evaluation. The state can be ``SUCCESS`` or ``FAILURE``.

            
          

          - **WindowStartDatetime** *(datetime) --* 

            The timestamp that indicates the start of the window that is used for monitor evaluation.

            
          

          - **WindowEndDatetime** *(datetime) --* 

            The timestamp that indicates the end of the window that is used for monitor evaluation.

            
          

          - **PredictorEvent** *(dict) --* 

            Provides details about a predictor event, such as a retraining.

            
            

            - **Detail** *(string) --* 

              The type of event. For example, ``Retrain``. A retraining event denotes the timepoint when a predictor was retrained. Any monitor results from before the ``Datetime`` are from the previous predictor. Any new metrics are for the newly retrained predictor.

              
            

            - **Datetime** *(datetime) --* 

              The timestamp for when the event occurred.

              
        
          

          - **MonitorDataSource** *(dict) --* 

            The source of the data the monitor resource used during the evaluation.

            
            

            - **DatasetImportJobArn** *(string) --* 

              The Amazon Resource Name (ARN) of the dataset import job used to import the data that initiated the monitor evaluation.

              
            

            - **ForecastArn** *(string) --* 

              The Amazon Resource Name (ARN) of the forecast the monitor used during the evaluation.

              
            

            - **PredictorArn** *(string) --* 

              The Amazon Resource Name (ARN) of the predictor resource you are monitoring.

              
        
          

          - **MetricResults** *(list) --* 

            A list of metrics Forecast calculated when monitoring a predictor. You can compare the value for each metric in the list to the metric's value in the  Baseline to see how your predictor's performance is changing.

            
            

            - *(dict) --* 

              An individual metric Forecast calculated when monitoring predictor usage. You can compare the value for this metric to the metric's value in the  Baseline to see how your predictor's performance is changing.

               

              For more information about metrics generated by Forecast see `Evaluating Predictor Accuracy <https://docs.aws.amazon.com/forecast/latest/dg/metrics.html>`__

              
              

              - **MetricName** *(string) --* 

                The name of the metric.

                
              

              - **MetricValue** *(float) --* 

                The value for the metric.

                
          
        
          

          - **NumItemsEvaluated** *(integer) --* 

            The number of items considered during the evaluation.

            
          

          - **Message** *(string) --* 

            Information about any errors that may have occurred during the monitor evaluation.

            
      
    
  
  **Exceptions**
  
  *   :py:class:`ForecastService.Client.exceptions.InvalidNextTokenException`

  
  *   :py:class:`ForecastService.Client.exceptions.InvalidInputException`

  
  *   :py:class:`ForecastService.Client.exceptions.ResourceNotFoundException`

  